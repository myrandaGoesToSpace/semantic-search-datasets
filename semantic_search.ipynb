{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "semantic_search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvmwuXg++id4MmoFllFM/7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myrandaGoesToSpace/semantic-search-datasets/blob/main/semantic_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMkwwzoDM4oB",
        "outputId": "8f0a7d95-82f2-4d39-d8d9-85ca04dbcc36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers>=0.10.3\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 17.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 30.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 18.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 22.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=120999 sha256=6395bcb34ad69007c358b0a26a13f0bb218c169762ac2cb6ea2703eabd6c96ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 sentence-transformers-2.1.0 sentencepiece-0.1.96 tokenizers-0.11.4 transformers-4.16.2\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install bs4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "K6AuxpNuNJB2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Example - semantic search\n",
        "\n",
        "query = \"How many people live in London?\"\n",
        "docs = [\"Around 9 Million people live in London\", \"London is known for its financial district\"]\n",
        "\n",
        "#Load the model\n",
        "model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
        "\n",
        "#Encode query and documents\n",
        "query_emb = model.encode(query)\n",
        "doc_emb = model.encode(docs)\n",
        "\n",
        "#Compute dot score between query and all document embeddings\n",
        "scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
        "\n",
        "#Combine docs & scores\n",
        "doc_score_pairs = list(zip(docs, scores))\n",
        "\n",
        "#Sort by decreasing score\n",
        "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "\n",
        "#Output passages & scores\n",
        "for doc, score in doc_score_pairs:\n",
        "    print(score, doc)\n",
        "  \n",
        "'''"
      ],
      "metadata": {
        "id": "RBJmXkeCNNG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "def find_abstracts(soup):\n",
        "  #df = pd.DataFrame(columns = [\"identifier\", \"abstract\"])\n",
        "  id_list = []\n",
        "  abs_list = []\n",
        "  title_list = []\n",
        "\n",
        "  for record in soup.find_all(\"csw:record\"):\n",
        "    id = record.find(\"dc:identifier\")\n",
        "    abs = record.find(\"dct:abstract\")\n",
        "    title = record.find(\"dc:title\")\n",
        "\n",
        "    # append id and abs to df\n",
        "    #df = df.append([id.text, abs.text])\n",
        "    id_list.append(id.text)\n",
        "    title_list.append(title.text)\n",
        "\n",
        "    if abs != None:\n",
        "      abs_list.append(abs.text)\n",
        "    else:\n",
        "      abs_list.append(\"NA\")\n",
        "\n",
        "  return id_list, title_list, abs_list\n",
        "\n",
        "# Get the abstracts from Geoportal\n",
        "URL = \"https://www.ncei.noaa.gov/metadata/geoportal/opensearch?f=csw&from=0&size=100&sort=title.sort\"\n",
        "\n",
        "page = requests.get(URL)\n",
        "soup = BeautifulSoup(page.text, \"lxml\")\n",
        "\n",
        "id_list, title_list, abs_list = find_abstracts(soup)\n",
        "df = pd.DataFrame(list(zip(id_list,title_list, abs_list)), columns = [\"identifier\", \"title\", \"abstract\"])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uKBtYAG4UF1P",
        "outputId": "9d70d516-a18c-4e5f-f6ee-ab04723bdb2f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e0642f00-73fb-44d1-ba5c-ff779d8bd60b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>identifier</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gov.noaa.nodc:0000662</td>\n",
              "      <td>(NCEI Accession 0000662)</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gov.noaa.nodc:0208737</td>\n",
              "      <td>(NCEI Accession 0208737)</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gov.noaa.nodc:0215155</td>\n",
              "      <td>(NCEI Accession 0215155)</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gov.noaa.ngdc.mgg.geophysics:G01414</td>\n",
              "      <td>1-deg x 1-deg Terrestrial Mean Free-Air Anomalies</td>\n",
              "      <td>The 1x1 degree Terrestrial Mean Free-Air Gravi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gov.noaa.nodc:0002166</td>\n",
              "      <td>11 Real-time XBT replacements assembled by Can...</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>ACUMEN2012</td>\n",
              "      <td>ACUMEN 2012: Atlantic Canyons Undersea Mapping...</td>\n",
              "      <td>Between February and August 2012, a team of NO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>gov.noaa.nodc:0231662</td>\n",
              "      <td>ADCP data collected aboard NOAA Ship Bell M. S...</td>\n",
              "      <td>This dataset includes ADCP data collected aboa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>gov.noaa.nodc:0226205</td>\n",
              "      <td>ADCP data collected aboard NOAA Ship Gordon Gu...</td>\n",
              "      <td>This dataset includes ADCP data collected aboa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>gov.noaa.nodc:0241017</td>\n",
              "      <td>ADCP data collected aboard NOAA Ship Nancy Fos...</td>\n",
              "      <td>This dataset includes ADCP data collected aboa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>gov.noaa.nodc:0240492</td>\n",
              "      <td>ADCP data collected aboard NOAA Ship Nancy Fos...</td>\n",
              "      <td>This dataset includes ADCP data collected aboa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0642f00-73fb-44d1-ba5c-ff779d8bd60b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0642f00-73fb-44d1-ba5c-ff779d8bd60b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0642f00-73fb-44d1-ba5c-ff779d8bd60b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             identifier  ...                                           abstract\n",
              "0                 gov.noaa.nodc:0000662  ...                                                 NA\n",
              "1                 gov.noaa.nodc:0208737  ...                                                 NA\n",
              "2                 gov.noaa.nodc:0215155  ...                                                 NA\n",
              "3   gov.noaa.ngdc.mgg.geophysics:G01414  ...  The 1x1 degree Terrestrial Mean Free-Air Gravi...\n",
              "4                 gov.noaa.nodc:0002166  ...                                                 NA\n",
              "..                                  ...  ...                                                ...\n",
              "95                           ACUMEN2012  ...  Between February and August 2012, a team of NO...\n",
              "96                gov.noaa.nodc:0231662  ...  This dataset includes ADCP data collected aboa...\n",
              "97                gov.noaa.nodc:0226205  ...  This dataset includes ADCP data collected aboa...\n",
              "98                gov.noaa.nodc:0241017  ...  This dataset includes ADCP data collected aboa...\n",
              "99                gov.noaa.nodc:0240492  ...  This dataset includes ADCP data collected aboa...\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make the abstracts the docs\n",
        "docs_df = df[df[\"abstract\"] != \"NA\"]\n",
        "docs = list(docs_df[\"abstract\"])\n",
        "titles = list(docs_df[\"title\"])\n",
        "\n",
        "# Query\n",
        "query = input(\"Enter your query: \")\n",
        "\n",
        "# predict on a search query for data\n",
        "\n",
        "#Load the model\n",
        "model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
        "\n",
        "#Encode query and documents\n",
        "query_emb = model.encode(query)\n",
        "doc_emb = model.encode(docs)\n",
        "\n",
        "#Compute dot score between query and all document embeddings\n",
        "scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
        "\n",
        "#Combine docs & scores\n",
        "doc_score_pairs = list(zip(docs, scores, titles))\n",
        "\n",
        "#Sort by decreasing score\n",
        "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "\n",
        "#Output passages & scores\n",
        "for doc, score, title in doc_score_pairs[:10]:\n",
        "    print(score, title, doc)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "f0_yph9dP6HW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09426584-8d5b-4d2c-88dc-72a843bcc801"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query: coral health in the Atlantic Ocean\n",
            "0.5344188809394836 A survey of selected coral and fish assemblages near the Waianae Ocean Outfall, Oahu, Hawaii, 1990-1999 (NCEI Accession 0000794) During 1990-1999, coral growth and fish abundance were monitored at stations located at and in the vicinity of the Waianae Ocean Outfall. Comparisons of results with fish surveys showed no significant differences in the species composition or relative abundances of fish populations at Station W-2 (the sunken ship Mahi), which is located 1.2 km south of the diffuser. Fish abundance and species richness increased at Station W- 3, which is located at the diffuser, from 1990 to 1995, decreased in 1996, and increased again in 1997 through 1999. At Station WW, an inshore station located 0.8 km from shore, fish were abundant and speciose on the armor rock covering the pipeline. The fish species seen inshore are comparable to fish species seen in similar (boulder) natural biotopes around Hawaii. There were no significant differences in total mean coral cover at selected quadrats from 1994 to 1999 at Station W-2. However, there was a significant increase (approximately 8%) in total mean coral cover at this station from 1991 to 1999. At the diffuser, corals were seen growing on the diffuser pipe and on the riser discharge ports. In 1986, when the diffuser began operation at a discharge rate of 1.5 mgd (0.07 m3/s), no corals were seen at this location. At inshore station WW, corals off the pipeline were sparsely distributed but were numerous and thriving on the armor rock over the pipeline. In 1998 the inshore transect (Alpha), off the armor rock, was covered (30%) with the alga Dictyopteris plagiogramma; however, in 1999 it disappeared. This seaweed was also abundant at this location in 1995, 1996, and 1997. The water was clear at all stations surveyed (13 to 20 m horizontal visibility), and the surrounding sediments were clean and white. No significant deleterious effect due to outfall operation and discharge were seen on the biological community at the stations surveyed. The increase in fish diversity and abundance at the diffuser since 1997 may be due to natural fluctuations in abundance or to environmental conditions suitable to the fish populations living there.\n",
            "\n",
            "\n",
            "0.4428386092185974 A combined global ocean pCO2 climatology combining open ocean and coastal areas (NCEI Accession 0209633) This NCEI accession contains the partial pressure of carbon dioxide (pCO2) climatology that was created by merging 2 published and publicly available pCO2 datasets covering the open ocean (Landschützer et. al 2016) and the coastal ocean (Laruelle et. al 2017). Both fields were initially created using a 2-step neural network technique. In a first step, the global ocean is divided into 16 biogeochemical provinces using a self-organizing map. In a second step, the non-linear relationship between variables known to drive the surface ocean carbon system and gridded observations from the SOCAT open and coastal ocean datasets (Bakker et. al 2016) is reconstructed using a feed-forward neural network within each province separately. The final product is then produced by projecting driving variables, e.g., surface temperature, chlorophyll, mixed layer depth, and atmospheric CO2 onto oceanic pCO2 using these non-linear relationships (see Landschützer et. al 2016 and Laruelle et. al 2017 for more detail). This results in monthly open ocean pCO2 fields at 1°x1° resolution and coastal ocean pCO2 fields at 0.25°x0.25° resolution. To merge the products, we divided each 1°x1° open ocean bin into 16 equal 0.25°x0.25° bins without any interpolation. The common overlap area of the products has been merged by scaling the respective products by their mismatch compared to observations from the SOCAT datasets (see Landschützer et. al 2020)\n",
            "\n",
            "\n",
            "0.4329672157764435 2013 Flower Garden Banks National Marine Sanctuary Long-Term Monitoring of the Reef Crest Benthic and Fish Communities of Stetson Bank, northwestern Gulf of Mexico (NCEI Accession 0246785) This dataset contains raw and processed data from an annual long-term monitoring study that documents the benthic and fish community changes at Stetson Bank, in the Flower Garden Banks National Marine Sanctuary. Stetson Bank is an uplifted claystone/siltstone feature, located 75 nautical miles from Galveston, TX in the northwestern Gulf of Mexico, that supports a well-developed benthic community of scleractinian coral and tropical marine sponges. Due to a wide range of temperatures and variable light availability, Stetson Bank has marginal environmental conditions for coral reef development and growth. The fish community is similar to other Caribbean reefs but has comparatively lower diversity.\n",
            "\n",
            "Monitoring has occurred on the bank crest (17-34 m) of the site since 1993. Bank crest monitoring includes random transect and repetitive photostation photographs of the benthos to estimate percent cover of major taxonomic groups (e.g., coral, sponge, algae). Benthic photographs are analyzed using Coral Point Count (CPCe) and output into Microsoft Excel worksheets. These data are analyzed for temporal community changes in Primer. Fish census surveys are conducted annually using a modified Bohnsack and Bannerot stationary method, both at random and repetitive sites. Fish data are recorded in Microsoft Excel worksheets. Primer software is used to identify any temporal shifts that occur in the fish community. Water quality parameters (e.g., temperature, salinity, turbidity, nutrients) are measured with moored conductivity temperature depth (CTD) instruments and quarterly profiles of the water column are performed. Temperature and salinity data are reduced to report daily averages.\n",
            "\n",
            "\n",
            "The bank crest benthic community at Stetson Bank has undergone several significant shifts, changing from a habitat predominated by hydrocoral and sponges to one of macroalgae and sponges. The fish community on the bank crest has varied annually. Exotic fish species are present at the bank, including lionfish (Pterois volitans/P. miles) and regal demoiselle (Neopomacentrus cyanomos). Fluctuations in oceanic conditions, macroalgae cover, and continued annual variation in fish communities were documented.\n",
            "\n",
            "\n",
            "0.4329672157764435 2014 Flower Garden Banks National Marine Sanctuary Long-Term Monitoring of the Reef Crest Benthic and Fish Communities of Stetson Bank, northwestern Gulf of Mexico (NCEI Accession 0244997) This dataset contains raw and processed data from an annual long-term monitoring study that documents the benthic and fish community changes at Stetson Bank, in the Flower Garden Banks National Marine Sanctuary. Stetson Bank is an uplifted claystone/siltstone feature, located 75 nautical miles from Galveston, TX in the northwestern Gulf of Mexico, that supports a well-developed benthic community of scleractinian coral and tropical marine sponges. Due to a wide range of temperatures and variable light availability, Stetson Bank has marginal environmental conditions for coral reef development and growth. The fish community is similar to other Caribbean reefs but has comparatively lower diversity.\n",
            "\n",
            "Monitoring has occurred on the bank crest (17-34 m) of the site since 1993. Bank crest monitoring includes random transect and repetitive photostation photographs of the benthos to estimate percent cover of major taxonomic groups (e.g., coral, sponge, algae). Benthic photographs are analyzed using Coral Point Count (CPCe) and output into Microsoft Excel worksheets. These data are analyzed for temporal community changes in Primer. Fish census surveys are conducted annually using a modified Bohnsack and Bannerot stationary method, both at random and repetitive sites. Fish data are recorded in Microsoft Excel worksheets. Primer software is used to identify any temporal shifts that occur in the fish community. Water quality parameters (e.g., temperature, salinity, turbidity, nutrients) are measured with moored conductivity temperature depth (CTD) instruments and quarterly profiles of the water column are performed. Temperature and salinity data are reduced to report daily averages.\n",
            "\n",
            "\n",
            "The bank crest benthic community at Stetson Bank has undergone several significant shifts, changing from a habitat predominated by hydrocoral and sponges to one of macroalgae and sponges. The fish community on the bank crest has varied annually. Exotic fish species are present at the bank, including lionfish (Pterois volitans/P. miles) and regal demoiselle (Neopomacentrus cyanomos). Fluctuations in oceanic conditions, macroalgae cover, and continued annual variation in fish communities were documented.\n",
            "\n",
            "\n",
            "0.4218589961528778 A combined globally mapped carbon dioxide (CO2) flux estimate based on the Surface Ocean CO2 Atlas Database (SOCAT) and Southern Ocean Carbon and Climate Observations and Modeling (SOCCOM) biogeochemistry floats from 1982 to 2017 (NCEI Accession 0191304) This NCEI accession contains a combined globally mapped estimate of the air-sea exchange of carbon dioxide (CO2) based on Surface Ocean CO2 Atlas Database (SOCAT) partial pressure of CO2 (pCO2) and calculated pCO2 from Southern Ocean Carbon and Climate Observations and Modeling (SOCCOM) biogeochemistry floats from 1982 to 2017. The pCO2 fields were created using a 2-step neural network technique. In a first step, the global ocean is divided into 16 biogeochemical provinces using a self-organizing map. In a second step, the non-linear relationship between variables known to drive the surface ocean carbon system and gridded observations from the SOCAT dataset (Bakker et al., 2016) starting in 1982 in various combinations with calculated pCO2 from biogeochemical ARGO floats starting in 2014 from the SOCCOM project (Johnson et al., 2017) is reconstructed using a feed-forward neural network within each province separately. The final product is then produced by projecting these driving variables, i.e., surface temperature, chlorophyll, mixed layer depth, and atmospheric CO2 onto oceanic pCO2 using these non-linear relationships. This results in monthly pCO2 fields at 1°x1° resolution covering the entire globe with the exception of the Arctic Ocean and few marginal seas. The air-sea CO2 flux is then computed using a standard bulk formula.\n",
            "\n",
            "\n",
            "0.39860960841178894 2019 Summer Hypoxia Survey of Alabama Shelf CTD Data (2019-06-04 to 2019-08-02) (NCEI Accession 0206155) Along the Fisheries Oceanography in Coastal Alabama (FOCAL) Transect on the Alabama shelf, a CTD survey was conducted using Seabird SBE 25 Sealogger CTD between 06/04/2019 and 08/02/2019. Data collected measured depth (m), salinity (PSU), temperature (ITS-90, deg C), oxygen (% Saturation), oxygen (mg/L), pH (pH), specific conductance (µS/cm), beam attenuation (1/m), beam transmission (%), density (kg/m3), conductivity (µS/cm), PAR (µmol m-1 s-1), fluorescence (mg/m3), and fluorescence (mg/m3). Data was collected on 2019-06-04, 2019-06-28, 2019-07-02, 2019-07-05, 2019-07-09, 2019-07-16, 2019-07-19, 2019-07-30, and 2019-08-02 during the summer of 2019.\n",
            "\n",
            "\n",
            "0.39455515146255493 A compilation of inorganic carbon system and other hydrographic and chemical discrete profile measurements obtained during the fifty five Line P cruises in the Northeast Pacific Ocean over the period from 1990 to 2019 (NCEI Accession 0234342) This NCEI Accession contains a compilation of inorganic carbon system and other hydrographic and chemical discrete profile measurements obtained during the fifty five Line P cruises in the Northeast Pacific Ocean over the period from 1990-05-10 to 2019-06-19. The data in the data set include dissolved inorganic carbon (DIC), total alkalinity (TA), water temperature, salinity, dissolved oxygen concentration and nutrients. The majority of the cruises from 1990 to 2015 have been reported elsewhere as individual files (e.g., GLODAP and PACIFICA databases). This data set is a combination of the available cruises into a single database, and extended the time series to June 2019. A secondary quality control was performed and the quality flags revised. Additionally, the suggested PACIFICA corrections for salinity, oxygen, dissolved inorganic carbon and nutrients were applied. Oxygen units were converted to µmol/kg when reported in ml/L. Nutrient concentrations were converted to µmol/kg from µmol/L.\n",
            "\n",
            "\n",
            "0.3915970027446747 A unified, long-term, Caribbean-wide initiative to identity the factors responsible for sustaining mangrove wetland, seagrass meadow, and coral reef productivity, February 1993 - October 1998 (NCEI Accession 0000501) The Caribbean Coastal Marine Productivity (CARICOMP) Program is a Caribbean-wide research and monitoring network of 27 marine laboratories, parks, and reserves in 17 countries. This data set includes data collected from 42 stations at 29 sites in the Caribbean from 1993 to 1998. Line transects were used to determine the abundance of hard and soft corals, algae, sponges, urchins, and biotic material such as substrate type.\n",
            "\n",
            "\n",
            "0.3857346773147583 A global monthly climatology of oceanic total dissolved inorganic carbon (DIC): a neural network approach (NCEI Accession 0222469) This NCEI accession contains global monthly climatology of oceanic total dissolved inorganic carbon (DIC). (DIC) monthly climatology was created from a neural network approach (Broullón et al., 2020). The neural network was trained with GLODAPv2.2019 (Olsen et al., 2019) and LDEOv2016 (Takahashi et al., 2017) data, using as predictor variables position (latitude, longitude and depth), year, temperature, salinity, phosphate, nitrate, silicate and dissolved oxygen. pCO2 from LDEOv2016 and AT from Broullón et al. (2019) were used to compute DIC surface values to increase the surface coverage in the training data. The relations extracted between the predictor variables and DIC were used to obtain the climatology passing through the network global monthly climatologies of the predictor variables: temperature and salinity fields of the World Ocean Atlas version 2013 (WOA13), filtered WOA13 oxygen (fifth-order one-dimensional median filter through the depth dimension; see Broullón et al., 2019 for details) and nutrients computed using CANYON-B (Bittig et al., 2018) over the three previous fields. The obtained climatology has a 1ºx1º spatial resolution and 102 depth levels between 0 and 5500 m, with a monthly resolution from 0 to 1500 m and an annual resolution from 1550 to 5500m.\n",
            "\n",
            "\n",
            "0.38015317916870117 A Toolbox for secondary quality control on ocean chemistry and hydrographic data (NCEI Accession 0209357) This NCEA Accession contains MatLab files for a Toolbox for secondary quality control (2nd QC) on ocean chemistry and hydrographic data.  High quality, reference measurements of chemical and physical properties of seawater are of great importance for a wide research community, including the need to validate models and attempts to quantify spatial and temporal variability. Whereas data precision has been improved by technological advances, the data accuracy has improved mainly by the use of certified reference materials (CRMs). However, since CRMs are not available for all variables, and use of CRMs does not guarantee bias-free data, we here present a recently developed Matlab toolbox for performing so-called secondary quality control on oceanographic data by the use of crossover analysis. This method and how it has been implemented in this toolbox is described in detail. This toolbox is developed mainly for use by sea-going scientists as a tool for quickly assessing possible bias in the measurements that can, hopefully, be remedied during the expedition, but also for possible post-cruise adjustment of data to be consistent with previous measurements in the region.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YiFMLlNzeoyr"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}